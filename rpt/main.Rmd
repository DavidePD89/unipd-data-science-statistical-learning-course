---
title: "Application of statistical analysis and modelling to Seoul Bike Sharing Demand dataset"
author: "Vasile Bezer (2124011), Second Student (12345678)"
font: 10pt
output:
  pdf_document:
    toc: true
    number_sections: true
  html_document:
    toc: false
  word_document:
    toc: false
---

\

# Introduction

A regression problem involves predicting a continuous numeric outcome using one or more input features. Linear regressors are based on the assumption that
there is a linear relationship between both the dependent variable and independent variables. This project focuses on the applications of linear regressors
on the Seoul Bike Sharing Demand dataset which incorporates real world bike sharing count of the city of Seoul with weather context ([the dataset can be retreived here](https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand)).
As major cities worldwide are moving towards smart mobility we hope to gain insight into how open-vehicle sharing systems could be optimized for efficiency
through out the year by finding relationships between number of shares and weather.

The outcomes of the project are expected to be the following:

1. Understanding the siginficance of weather on bike sharing systems
2. Ability to estimate bike count required at each hour
3. Building statistical models exploiting this dataset

\

# Dataset insight

We proceed our in depth look at the dataset by importing and looking at the summary. The format of the dataset is csv, to read it
we use the built-in function read.csv of R.

```{r}
seoul.bike.data <- read.csv(
	file = "../data/SeoulBikeData.csv"
	,sep = ","
);
nrow(seoul.bike.data); ncol(seoul.bike.data); summary(seoul.bike.data);
```

We notice that the proposed dataset consists of 1 target, namely Rented Bike count, and 13 predictors whose characteristics are described by 8760 rows.
The description of each predictor is given by the dataset's source as follows:

| Variable Name         | Description                                          | Role    | Type        | Units | Missing Values |
| :-------------------- | :--------------------------------------------------- | :------ | :---------- | :---: | :------------- |
| Date                  | year-month-day                                       | Feature | Date        |       | no             |
| Rented Bike count     | Count of bikes rented at each hour                   | Feature | Integer     |       | no             |
| Hour                  | Hour of the day                                      | Feature | Integer     |       | no             |
| Temperature           | Temperature in Celsius                               | Feature | Continuous  |   C   | no             |
| Humidity              | %                                                    | Feature | Integer     |   %   | no             |
| Windspeed             | m/s                                                  | Feature | Continuous  |  m/s  | no             |
| Visibility            | 10m                                                  | Feature | Integer     |  10m  | no             |
| Dew point temperature | Celsius                                              | Feature | Continuous  |   C   | no             |
| Solar radiation       | MJ/m2                                                | Feature | Continuous  | Mj/m2 | no             |
| Rainfall              | mm                                                   | Feature | Integer     |  mm   | no             |
| Snowfall              | cm                                                   | Feature | Integer     |  cm   | no             |
| Seasons               | Winter, Spring, Summer, Autumn                       | Feature | Categorical |       | no             |
| Holiday               | Holiday/No holiday                                   | Feature | Binary      |       | no             |
| Functional Day        | NoFunc (Non-Functional Hours), Fun(Functional hours) | Feature | Binary      |       | no             |

## Missing value imputation

We notice that none of the predictors are reported as missing in the dataset's source, we proceed by checking this fact:

```{r}
ceiling( colSums(is.na(seoul.bike.data)) / nrow(seoul.bike.data) * 100 );
```

A key part of data preprocessing is dealing with missing values. These gaps can happen due to incomplete information or other reasons.
If not handled properly, they can result in incorrect predictions. It's important to find and fix any missing values but
in our case this dataset doesn't present this problem.

Here we also want to make sure that the dataset is coherent with itself. Specifically, we want to make sure that 
when the system is not operative there are no erroneous shares.
```{r}
sum(seoul.bike.data$Rented.Bike.Count[seoul.bike.data$Functioning.Day == "No"]);
sum(seoul.bike.data$Rented.Bike.Count[seoul.bike.data$Functioning.Day == "Yes"]);
```

## Data preprocessing

Our dataset contains the following categorical variables: Seasons, Holiday, Functional Day. As seen before R treats them
as character variables but we need to we therefore proceed to transform them into factors for R to interpret them correctly.

```{r}
seoul.bike.data$Seasons 		<- factor( seoul.bike.data$Seasons );
seoul.bike.data$Holiday 		<- factor( seoul.bike.data$Holiday, ordered = TRUE );
seoul.bike.data$Functioning.Day <- factor( seoul.bike.data$Functioning.Day );
```

Transforming everything into factors servers the following purpose

We also need to transform our predictors Date and Hour into a date format correctly interpretable by R.

```{r}
seoul.bike.data$tmstmp <- strptime(
	paste( seoul.bike.data$Date, seoul.bike.data$Hour )
	,format="%d/%m/%Y %H"
);
seoul.bike.data$Date <- as.Date( seoul.bike.data$Date, format="%d/%m/%Y" );
seoul.bike.data$tmstmp <- as.Date( seoul.bike.data$tmstmp );
```

Finally, we add the intercept to our data and transform the dataset into a matrix format.

```{r}
seoul.bike.datam <- cbind(1, seoul.bike.data);
seoul.bike.datam <- as.matrix( seoul.bike.data );
```

## Outliers and high-leverage points



\

# Exploratory Data analysis

We begin this section of EDA by taking a look at the correlation matrix for our continuous predictors.


```{r}

```

## Correlation matrix

In order to find linear relationships between our continuous predictors our first step is to build
a correlation matrix.

```{r}
library(corrplot, warn.conflicts = FALSE); corrplot(
	cor(seoul.bike.data[2:11])
	,method = "number"
	,diag = FALSE
	,tl.cex = 0.8
	,number.cex = 0.6
	,tl.col = "black"
	);
```

The most important predictors, in linear terms, for our target seem to be Temperature, Hour and Dew point temperature. We can also
notice how Temperature and Dew point temperature are highly correlated which signifies that there might be
a confounding effect taking place.
In the next paragraph, our objective is to investigate the most siginficant correlations with our target.

## Partial correlation graph

Partial correlation allows us to investigate the presence of linear relationships between variables with the effect of a set of controlling random
variables removed. This in turn allows us to capture relationships more in depth compared to the classic correlation matrix. We proceed to build this graph
by using the treshold method.

```{r}
library(igraph, warn.conflicts = FALSE); library(gRbase, warn.conflicts = FALSE);

threshold <- 1/5;
variance.matrix <- var( seoul.bike.data[2:11], use="pairwise.complete.obs" );
covariance.matrix <- -cov2cor( solve(variance.matrix) );
independence.matrix <- abs( covariance.matrix ) > threshold;
diag(independence.matrix) <- 0; # remove self dependencies
independence.graph <- as( independence.matrix, "igraph" );
plot(independence.graph);
```

We can notice how the graph clearly presents us with the fact that our target is correlated with a multitude of predictors in our dataset.
On the contrary, Snowfall and Rainfall seem to not be linaerly correlated to the target but this fact alone does not mean we should remove
these variables from our analysis.

## Scatter plots

We now try plotting our target, in our case Rented Bike count, against the new timestamp variable we created
to see if we can notice any trends. With the help of a legend we split the dataset into all 4 seasons.

```{r}
ssn.clr = c("Spring" = "#78C850", "Summer" = "#FFB14E"
	,"Autumn" = "#DC143C", "Winter" = "#4B8BBE");
plot(seoul.bike.data$tmstmp, seoul.bike.data$Rented.Bike.Count
	,col = ssn.clr[seoul.bike.data$Season], pch = 16
	,cex = 0.5, main = "Rented Bike count vs. Timestamp"
	,xlab = "Timestamp",ylab = "Rented Bike count" );
legend("topleft", legend = names(ssn.clr), col = ssn.clr
  ,pch = 16, title = "Season", cex = 0.7);
```

Here we notice how bike share demand peaks in summer and declines in winter implying that the bike
shares are high when the weather is warm.

```{r}
hr.clr <- colorRampPalette( c("#D0E1F9", "#4B8BBE", "#1D4E89") )(24)
plot(seoul.bike.data$tmstmp, seoul.bike.data$Rented.Bike.Count
	,col = hr.clr[seoul.bike.data$Hour], pch = 16
	,cex = 0.5, main = "Rented Bike count vs. Timestamp"
	,xlab = "Timestamp", ylab = "Rented Bike count");
legend("topleft", ncol = 3, legend = seq(1,24), col = hr.clr
  ,pch = 16, title = "Hour", cex = 0.7);
```

This plot allows us to notice that although the target is indeed influenced by Hour, the influence is not as
strong as for Temperature conforming with the result obtained in the correlation matrix.

We now proceed to plot our target against Temperature to see if our assumptions have any foundation.

```{r}
hr.clr <- colorRampPalette(c("#6A3D9A", "#984EA3", "#7570B3", "#D95F0E", "#FF7F00"))(24)
plot(seoul.bike.data$Temperature, seoul.bike.data$Rented.Bike.Count
	,col = hr.clr[seoul.bike.data$Hour], pch = 16
	,cex = 0.5, main = "Rented Bike count vs. Temperature"
	,xlab = "Temperature", ylab = "Rented Bike count");
legend("topleft", ncol = 3, legend = seq(1,24), col = hr.clr
  ,pch = 16, title = "Hour", cex = 0.7);
```

This plot shows us how bike shares are indeed influenced by temperature in a mostly linear manner.
Although the correlation between target and Hour is relatively significant, by inspecting this scatter plot
we cannot conclude that this is true.

```{r}
par(mfrow = c(2, 2));
boxplot(Rented.Bike.Count ~ weekdays(seoul.bike.data$tmstmp), data = seoul.bike.data, 
        xlab = "Day of the Week", ylab = "Rented Bike count"
		,main = "Rented Bike cnt vs. Day of the Week"
		,col = c("lightpink", "lightblue", "lightgreen", "lightcoral", "lightgoldenrod", "lightcyan", "lavender"));
plot(seoul.bike.data$Humidity, seoul.bike.data$Rented.Bike.Count, 
     xlab = "Humidity (%)", ylab = "Rented Bike count", 
     main = "Rented Bike cnt vs. Humidity", 
     col =  c("lightgreen", "mediumseagreen", "darkseagreen", "palegreen"), pch = 16, cex = 0.7);
plot(seoul.bike.data$Wind.speed, seoul.bike.data$Rented.Bike.Count, 
     xlab = "Wind Speed (m/s)", ylab = "Rented Bike count", 
     main = "Rented Bike cnt vs. Wind Speed", 
     col = "#7469B6", pch = 16, cex = 0.7);
```
```{r}
classify_weather <- function(wind_speed, humidity, temperature, visibility, solar_radiation, rainfall, snowfall) {
  if (rainfall > 0 | snowfall > 0) {
    return("Wet")
  } else if (solar_radiation > 0.5) {
    return("Sunny")
  } else if (temperature < 0) {
    return("Cold")
  } else if (temperature > 25) {
    return("Hot")
  } else if (humidity > 80) {
    return("Humid")
  } else if (wind_speed > 5) {
    return("Windy")
  } else {
    return("Moderate")
  }
}

# Apply the function to create a new weather variable
seoul.bike.data$Weather <- mapply(classify_weather, 
                                  seoul.bike.data$Wind.speed, 
                                  seoul.bike.data$Humidity, 
                                  seoul.bike.data$Temperature, 
                                  seoul.bike.data$Visibility, 
                                  seoul.bike.data$Solar.Radiation, 
                                  seoul.bike.data$Rainfall, 
                                  seoul.bike.data$Snowfall)

boxplot(Rented.Bike.Count ~ Weather, data = seoul.bike.data, 
        xlab = "Weather Condition", ylab = "Bike Count", 
        main = "Bike Count vs. Weather Condition", 
        col = c("skyblue", "lightgreen", "orange", "lightcoral", "lightgoldenrod", "lightcyan", "lavender"),
        border = "black", las = 1, cex.axis = 0.8)

# Optional: Add mean points
means <- tapply(seoul.bike.data$Rented.Bike.Count, seoul.bike.data$Weather, mean)
points(1:length(means), means, col = "red", pch = 18)
count_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  outliers <- x[x < lower_bound | x > upper_bound]
  return(length(outliers))
}

# Apply the function to each category in the dataset
outlier_counts <- tapply(seoul.bike.data$Rented.Bike.Count, seoul.bike.data$Weather, count_outliers)

# Print the number of outliers for each category
print(outlier_counts)
```


```{r}


# Assign weights to each variable based on assumed or known importance
# Adjust weights to ensure the sum results in a non-negative score
# These weights can be adjusted based on domain knowledge or data analysis
weights <- c(Temperature = 0.25, Humidity = 0.15, WindSpeed = 0.10, 
             Visibility = 0.20, SolarRadiation = 0.15, Rainfall = 0.05, Snowfall = 0.10)

# Calculate the weather score as a weighted sum of the standardized variables
seoul.bike.data$WeatherScore <- (weights["Temperature"] * seoul.bike.data$Temperature +
                                 weights["Humidity"] * seoul.bike.data$Humidity +
                                 weights["WindSpeed"] * seoul.bike.data$Wind.speed +
                                 weights["Visibility"] * seoul.bike.data$Visibility +
                                 weights["SolarRadiation"] * seoul.bike.data$Solar.Radiation +
                                 weights["Rainfall"] * seoul.bike.data$Rainfall +
                                 weights["Snowfall"] * seoul.bike.data$Snowfall)
hr.clr <- colorRampPalette(c("red", "yellow", "green"))(24)
plot(log(seoul.bike.data$WeatherScore), seoul.bike.data$Rented.Bike.Count
	,col = hr.clr[seoul.bike.data$Hour], pch = 16
	,cex = 0.5, main = "Rented Bike count vs. WeatherScore"
	,xlab = "WeatherScore", ylab = "Rented Bike count");
legend("topleft", ncol = 3, legend = seq(1,24), col = hr.clr
  ,pch = 16, title = "Hour", cex = 0.7);
```


## Distribution

```{r}
par(mfrow = c(3, 4));
for (i in 2:11) {
  hist(seoul.bike.data[[i]], main = paste("Histogram of", names(seoul.bike.data)[i])
  	,xlab = names(seoul.bike.data)[i], col = "skyblue", border = "white", cex.main = 0.8);
}
# par(mfrow = c(1, 1));
```

# Modelling
In this step you may, for example, use regression and predictions for forecasting future
values, and classification to identify groups.
One of the first things you need to do in modelling data is to reduce the dimensionality
of your data set. Not all your features or values are essential to predicting your model.
What you need to do is to select the relevant ones that contribute to the prediction
of results or apply shrinkage regressions.


We proceed with modelling several predictive models covered during the course:

1. Multiple Linear Regressor
2. Poisson Regressor
3. Ridge Regression
4. Lasso Regression

## Diagnostics

## Residual analysis

## Outliers and high-leverage points

## Collinearity

## ANOVA



# Conclusions

Interpreting data refers to the presentation of your analysis. Technical details are nec-
essary but make an effort to make you presentation accessible also to a non-technical
audience. You should deliver the results to answer the questions you asked when we
first started the project, together with the actionable insights that you found through
the process.
In this process, technical skills only are not sufficient. One essential skill you need is
to be able to tell a clear and actionable story.